{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import easynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easynlp.fewshot_learning.fewshot_predictor import PromptMultiLayerPredictor\n",
    "from easynlp.fewshot_learning.fewshot_application import FewshotMultiLayerClassification\n",
    "# 重载\n",
    "module = importlib.import_module(PromptMultiLayerPredictor.__module__)\n",
    "importlib.reload(module)\n",
    "PromptMultiLayerPredictor = module.PromptMultiLayerPredictor\n",
    "FewshotPyModelPredictor = module.FewshotPyModelPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label(label_file, model_dir):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "    # 先解析 label\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        # 这边 id 是 int\n",
    "        label2id = json.load(f)\n",
    "        label2id = {k: str(v) for k, v in label2id.items()}\n",
    "\n",
    "    # 想想每一层的标签应该怎么建立, 现在假设每层都是完整的, 也就是每个样本的标签都会到最后一层\n",
    "    label_enumerate_values = defaultdict(list)\n",
    "    label_desc = defaultdict(list)\n",
    "    for label, label_id in label2id.items():\n",
    "        label_split = label.split(\">\")\n",
    "        # 标签应该只放最后一层的. TODO: 同名怎么办?\n",
    "        idx = len(label_split) - 1\n",
    "        label_enumerate_values[idx].append(label_id)\n",
    "        label_desc[idx].append(label_split[-1])\n",
    "\n",
    "    # 其实应该还是有序的, 因为添加的时候是从左到右添加的\n",
    "    # 计算 label_desc 的最大长度\n",
    "    for idx in sorted(label_desc.keys()):\n",
    "        cur_list = label_desc[idx]\n",
    "        cur_max_len = max([len(tokenizer.tokenize(x)) for x in cur_list])\n",
    "        print(f\"layer_{idx}, max_label_len: {cur_max_len}\")\n",
    "        # 填充到最大长度\n",
    "        label_desc[idx] = [x + \"[PAD]\" * (cur_max_len - len(tokenizer.tokenize(x))) for x in cur_list]\n",
    "\n",
    "    label_enumerate_values_new = []\n",
    "    for idx in sorted(label_enumerate_values.keys()):\n",
    "        label_enumerate_values_new.append(\",\".join(label_enumerate_values[idx]))\n",
    "    label_enumerate_values_new = \"@@\".join(label_enumerate_values_new)\n",
    "\n",
    "    label_desc_new = []\n",
    "    for idx in sorted(label_desc.keys()):\n",
    "        label_desc_new.append(\",\".join(label_desc[idx]))\n",
    "    label_desc_new = \"@@\".join(label_desc_new)\n",
    "\n",
    "    return label_enumerate_values_new, label_desc_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0, max_label_len: 4\n",
      "layer_1, max_label_len: 5\n"
     ]
    }
   ],
   "source": [
    "model_dir = r\"G:\\code\\github\\EasyNLP\\demo\\tmp\\fewshot_multi_layer\"\n",
    "input_schema = \"text:str:1,label0:str:1,label1:str:1\"\n",
    "label_name = \"label0,label1\"\n",
    "pattern = \"一条,label0,label1,的新闻,text\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\网页层次分类\\label.json\"\n",
    "label_enumerate_values, label_desc = parse_label(label_file, model_dir)\n",
    "\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    label2id = json.load(f)\n",
    "    label2id = {k: str(v) for k, v in label2id.items()}\n",
    "    id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size: 21128\n"
     ]
    }
   ],
   "source": [
    "predictor = PromptMultiLayerPredictor(\n",
    "    model_dir=model_dir,\n",
    "    model_cls=FewshotMultiLayerClassification,\n",
    "    user_defined_parameters={\n",
    "        \"app_parameters\": {\n",
    "            \"pattern\": pattern,\n",
    "            \"label_desc\": label_desc,\n",
    "        }\n",
    "    },\n",
    "    first_sequence=\"text\",\n",
    "    second_sequence=None,\n",
    "    label_name=label_name,\n",
    "    sequence_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_0 0 休闲娱乐\n",
      "predictions_1 1 休闲娱乐>影视音乐\n"
     ]
    }
   ],
   "source": [
    "text = \"荔枝壳 专注于云计算、大数据等IT技术，以及最新动态资讯\"\n",
    "result = predictor.run({\"text\": text})\n",
    "result\n",
    "for key, val in result.items():\n",
    "    if key.startswith(\"predictions\"):\n",
    "        print(key, val, id2label[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 21128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = predictor.preprocess({\"text\": \"华孚时尚股份有限公司 华孚时尚股份有限公司\"})\n",
    "predictor.predict(inputs)[\"logits\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
