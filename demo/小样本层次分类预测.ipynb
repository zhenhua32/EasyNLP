{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import easynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easynlp.fewshot_learning.fewshot_predictor import PromptMultiLayerPredictor\n",
    "from easynlp.fewshot_learning.fewshot_application import FewshotMultiLayerClassification\n",
    "# 重载\n",
    "module = importlib.import_module(PromptMultiLayerPredictor.__module__)\n",
    "importlib.reload(module)\n",
    "PromptMultiLayerPredictor = module.PromptMultiLayerPredictor\n",
    "FewshotPyModelPredictor = module.FewshotPyModelPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label(label_file, model_dir):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "    # 先解析 label\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        # 这边 id 是 int\n",
    "        label2id = json.load(f)\n",
    "        label2id = {k: str(v) for k, v in label2id.items()}\n",
    "\n",
    "    # 想想每一层的标签应该怎么建立, 现在假设每层都是完整的, 也就是每个样本的标签都会到最后一层\n",
    "    label_enumerate_values = defaultdict(list)\n",
    "    label_desc = defaultdict(list)\n",
    "    for label, label_id in label2id.items():\n",
    "        label_split = label.split(\">\")\n",
    "        # 标签应该只放最后一层的. TODO: 同名怎么办?\n",
    "        idx = len(label_split) - 1\n",
    "        label_enumerate_values[idx].append(label_id)\n",
    "        label_desc[idx].append(label_split[-1])\n",
    "\n",
    "    # 其实应该还是有序的, 因为添加的时候是从左到右添加的\n",
    "    # 计算 label_desc 的最大长度\n",
    "    for idx in sorted(label_desc.keys()):\n",
    "        cur_list = label_desc[idx]\n",
    "        cur_max_len = max([len(tokenizer.tokenize(x)) for x in cur_list])\n",
    "        print(f\"layer_{idx}, max_label_len: {cur_max_len}\")\n",
    "        # 填充到最大长度\n",
    "        label_desc[idx] = [x + \"[PAD]\" * (cur_max_len - len(tokenizer.tokenize(x))) for x in cur_list]\n",
    "\n",
    "    label_enumerate_values_new = []\n",
    "    for idx in sorted(label_enumerate_values.keys()):\n",
    "        label_enumerate_values_new.append(\",\".join(label_enumerate_values[idx]))\n",
    "    label_enumerate_values_new = \"@@\".join(label_enumerate_values_new)\n",
    "\n",
    "    label_desc_new = []\n",
    "    for idx in sorted(label_desc.keys()):\n",
    "        label_desc_new.append(\",\".join(label_desc[idx]))\n",
    "    label_desc_new = \"@@\".join(label_desc_new)\n",
    "\n",
    "    return label_enumerate_values_new, label_desc_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0, max_label_len: 4\n",
      "layer_1, max_label_len: 5\n"
     ]
    }
   ],
   "source": [
    "model_dir = r\"G:\\code\\github\\EasyNLP\\demo\\tmp\\fewshot_multi_layer\"\n",
    "input_schema = \"text:str:1,label0:str:1,label1:str:1\"\n",
    "label_name = \"label0,label1\"\n",
    "pattern = \"一条,label0,label1,的新闻,text\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\网页层次分类\\label.json\"\n",
    "label_enumerate_values, label_desc = parse_label(label_file, model_dir)\n",
    "\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    label2id = json.load(f)\n",
    "    label2id = {k: str(v) for k, v in label2id.items()}\n",
    "    id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size: 21128\n"
     ]
    }
   ],
   "source": [
    "predictor = PromptMultiLayerPredictor(\n",
    "    model_dir=model_dir,\n",
    "    model_cls=FewshotMultiLayerClassification,\n",
    "    user_defined_parameters={\n",
    "        \"app_parameters\": {\n",
    "            \"pattern\": pattern,\n",
    "            \"label_desc\": label_desc,\n",
    "        }\n",
    "    },\n",
    "    first_sequence=\"text\",\n",
    "    second_sequence=None,\n",
    "    label_name=label_name,\n",
    "    sequence_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_0 7 电脑网络\n",
      "predictions_1 19 商业经济>商务服务\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ebe710a2-3db3-4f5d-bc59-7de749f8ba8f',\n",
       " 'output_0': [{'pred': '7', 'log_probability': -5.37250554561615},\n",
       "  {'pred': '31', 'log_probability': -6.49626100063324},\n",
       "  {'pred': '21', 'log_probability': -6.822508215904236},\n",
       "  {'pred': '13', 'log_probability': -6.908230185508728},\n",
       "  {'pred': '42', 'log_probability': -9.892513513565063},\n",
       "  {'pred': '37', 'log_probability': -12.434987306594849},\n",
       "  {'pred': '0', 'log_probability': -17.626222133636475}],\n",
       " 'predictions_0': '7',\n",
       " 'output_1': [{'pred': '19', 'log_probability': -22.53544795513153},\n",
       "  {'pred': '11', 'log_probability': -24.47456192970276},\n",
       "  {'pred': '36', 'log_probability': -24.623088121414185},\n",
       "  {'pred': '40', 'log_probability': -27.03253197669983},\n",
       "  {'pred': '30', 'log_probability': -27.18796133995056},\n",
       "  {'pred': '5', 'log_probability': -27.41420817375183},\n",
       "  {'pred': '44', 'log_probability': -27.634508848190308},\n",
       "  {'pred': '39', 'log_probability': -27.64013385772705},\n",
       "  {'pred': '45', 'log_probability': -29.38923978805542},\n",
       "  {'pred': '10', 'log_probability': -29.688742637634277},\n",
       "  {'pred': '35', 'log_probability': -30.49739360809326},\n",
       "  {'pred': '8', 'log_probability': -30.900529503822327},\n",
       "  {'pred': '41', 'log_probability': -31.075814962387085},\n",
       "  {'pred': '38', 'log_probability': -32.03236770629883},\n",
       "  {'pred': '9', 'log_probability': -32.091472148895264},\n",
       "  {'pred': '12', 'log_probability': -32.27565336227417},\n",
       "  {'pred': '33', 'log_probability': -32.353188276290894},\n",
       "  {'pred': '32', 'log_probability': -33.25011682510376},\n",
       "  {'pred': '34', 'log_probability': -33.32839822769165},\n",
       "  {'pred': '22', 'log_probability': -34.072025775909424},\n",
       "  {'pred': '46', 'log_probability': -34.145466566085815},\n",
       "  {'pred': '29', 'log_probability': -34.955074310302734},\n",
       "  {'pred': '16', 'log_probability': -36.350646018981934},\n",
       "  {'pred': '43', 'log_probability': -36.54642963409424},\n",
       "  {'pred': '26', 'log_probability': -37.302659034729004},\n",
       "  {'pred': '4', 'log_probability': -37.536677837371826},\n",
       "  {'pred': '20', 'log_probability': -37.82399845123291},\n",
       "  {'pred': '6', 'log_probability': -37.990464210510254},\n",
       "  {'pred': '25', 'log_probability': -38.95689916610718},\n",
       "  {'pred': '15', 'log_probability': -39.02124309539795},\n",
       "  {'pred': '47', 'log_probability': -39.18665289878845},\n",
       "  {'pred': '3', 'log_probability': -40.59006977081299},\n",
       "  {'pred': '2', 'log_probability': -40.918299198150635},\n",
       "  {'pred': '18', 'log_probability': -42.00903558731079},\n",
       "  {'pred': '1', 'log_probability': -42.29172229766846},\n",
       "  {'pred': '28', 'log_probability': -42.39668083190918},\n",
       "  {'pred': '23', 'log_probability': -44.61000442504883},\n",
       "  {'pred': '24', 'log_probability': -45.18373489379883},\n",
       "  {'pred': '27', 'log_probability': -45.78418731689453},\n",
       "  {'pred': '17', 'log_probability': -50.57694435119629},\n",
       "  {'pred': '14', 'log_probability': -51.78725719451904}],\n",
       " 'predictions_1': '19'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"博金翻译公司 笔记本网\"\n",
    "result = predictor.run({\"text\": text})\n",
    "for key, val in result.items():\n",
    "    if key.startswith(\"predictions\"):\n",
    "        print(key, val, id2label[val])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
