{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import easynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easynlp.fewshot_learning.fewshot_predictor import PromptMultiLayerPredictor\n",
    "from easynlp.fewshot_learning.fewshot_application import FewshotMultiLayerClassification\n",
    "# 重载\n",
    "module = importlib.import_module(PromptMultiLayerPredictor.__module__)\n",
    "importlib.reload(module)\n",
    "PromptMultiLayerPredictor = module.PromptMultiLayerPredictor\n",
    "FewshotPyModelPredictor = module.FewshotPyModelPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label(label_file, model_dir):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "    # 先解析 label\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        # 这边 id 是 int\n",
    "        label2id = json.load(f)\n",
    "        label2id = {k: str(v) for k, v in label2id.items()}\n",
    "\n",
    "    # 想想每一层的标签应该怎么建立, 现在假设每层都是完整的, 也就是每个样本的标签都会到最后一层\n",
    "    label_enumerate_values = defaultdict(list)\n",
    "    label_desc = defaultdict(list)\n",
    "    for label, label_id in label2id.items():\n",
    "        label_split = label.split(\">\")\n",
    "        # 标签应该只放最后一层的. TODO: 同名怎么办?\n",
    "        idx = len(label_split) - 1\n",
    "        label_enumerate_values[idx].append(label_id)\n",
    "        label_desc[idx].append(label_split[-1])\n",
    "\n",
    "    # 其实应该还是有序的, 因为添加的时候是从左到右添加的\n",
    "    # 计算 label_desc 的最大长度\n",
    "    for idx in sorted(label_desc.keys()):\n",
    "        cur_list = label_desc[idx]\n",
    "        cur_max_len = max([len(tokenizer.tokenize(x)) for x in cur_list])\n",
    "        print(f\"layer_{idx}, max_label_len: {cur_max_len}\")\n",
    "        # 填充到最大长度\n",
    "        label_desc[idx] = [x + \"[PAD]\" * (cur_max_len - len(tokenizer.tokenize(x))) for x in cur_list]\n",
    "\n",
    "    label_enumerate_values_new = []\n",
    "    for idx in sorted(label_enumerate_values.keys()):\n",
    "        label_enumerate_values_new.append(\",\".join(label_enumerate_values[idx]))\n",
    "    label_enumerate_values_new = \"@@\".join(label_enumerate_values_new)\n",
    "\n",
    "    label_desc_new = []\n",
    "    for idx in sorted(label_desc.keys()):\n",
    "        label_desc_new.append(\",\".join(label_desc[idx]))\n",
    "    label_desc_new = \"@@\".join(label_desc_new)\n",
    "\n",
    "    return label_enumerate_values_new, label_desc_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0, max_label_len: 4\n",
      "layer_1, max_label_len: 5\n"
     ]
    }
   ],
   "source": [
    "model_dir = r\"G:\\code\\github\\EasyNLP\\demo\\tmp\\fewshot_multi_layer_0\"\n",
    "input_schema = \"text:str:1,label0:str:1,label1:str:1\"\n",
    "label_name = \"label0,label1\"\n",
    "pattern = \"一条,label0,label1,的新闻,text\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\网页层次分类\\label.json\"\n",
    "label_enumerate_values, label_desc = parse_label(label_file, model_dir)\n",
    "\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    label2id = json.load(f)\n",
    "    label2id = {k: str(v) for k, v in label2id.items()}\n",
    "    id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size: 21128\n"
     ]
    }
   ],
   "source": [
    "predictor = PromptMultiLayerPredictor(\n",
    "    model_dir=model_dir,\n",
    "    model_cls=FewshotMultiLayerClassification,\n",
    "    user_defined_parameters={\n",
    "        \"app_parameters\": {\n",
    "            \"pattern\": pattern,\n",
    "            \"label_desc\": label_desc,\n",
    "        }\n",
    "    },\n",
    "    first_sequence=\"text\",\n",
    "    second_sequence=None,\n",
    "    label_name=label_name,\n",
    "    sequence_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_0 31 教育文化\n",
      "predictions_1 19 商业经济>商务服务\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '7f454c0b-4de6-4702-8de6-59a56f08ee70',\n",
       " 'output_0': [{'pred': '31', 'log_probability': -3.4901514649391174},\n",
       "  {'pred': '13', 'log_probability': -4.1239500641822815},\n",
       "  {'pred': '7', 'log_probability': -7.617522358894348},\n",
       "  {'pred': '42', 'log_probability': -14.757622718811035},\n",
       "  {'pred': '21', 'log_probability': -15.344586372375488},\n",
       "  {'pred': '37', 'log_probability': -19.164406776428223},\n",
       "  {'pred': '0', 'log_probability': -24.768311500549316}],\n",
       " 'predictions_0': '31',\n",
       " 'output_1': [{'pred': '19', 'log_probability': -5.100216098129749},\n",
       "  {'pred': '33', 'log_probability': -6.037768550217152},\n",
       "  {'pred': '9', 'log_probability': -8.443211741745472},\n",
       "  {'pred': '40', 'log_probability': -9.353070385754108},\n",
       "  {'pred': '8', 'log_probability': -10.011634059250355},\n",
       "  {'pred': '10', 'log_probability': -11.035785913467407},\n",
       "  {'pred': '30', 'log_probability': -11.49838937073946},\n",
       "  {'pred': '36', 'log_probability': -12.143209584057331},\n",
       "  {'pred': '11', 'log_probability': -12.34598172456026},\n",
       "  {'pred': '32', 'log_probability': -13.14862359315157},\n",
       "  {'pred': '35', 'log_probability': -13.525432713329792},\n",
       "  {'pred': '34', 'log_probability': -14.427461750805378},\n",
       "  {'pred': '44', 'log_probability': -16.240321286022663},\n",
       "  {'pred': '16', 'log_probability': -17.363042004406452},\n",
       "  {'pred': '12', 'log_probability': -17.544970639050007},\n",
       "  {'pred': '45', 'log_probability': -17.560599453747272},\n",
       "  {'pred': '43', 'log_probability': -17.667688496410847},\n",
       "  {'pred': '41', 'log_probability': -18.055758602917194},\n",
       "  {'pred': '22', 'log_probability': -18.259364254772663},\n",
       "  {'pred': '18', 'log_probability': -19.088515408337116},\n",
       "  {'pred': '25', 'log_probability': -19.245309956371784},\n",
       "  {'pred': '39', 'log_probability': -19.415945179760456},\n",
       "  {'pred': '29', 'log_probability': -19.59654725342989},\n",
       "  {'pred': '5', 'log_probability': -19.899259693920612},\n",
       "  {'pred': '47', 'log_probability': -21.802623875439167},\n",
       "  {'pred': '15', 'log_probability': -22.087170727550983},\n",
       "  {'pred': '17', 'log_probability': -27.287988789379597},\n",
       "  {'pred': '2', 'log_probability': -27.52737296372652},\n",
       "  {'pred': '4', 'log_probability': -28.429701454937458},\n",
       "  {'pred': '28', 'log_probability': -29.25448764115572},\n",
       "  {'pred': '20', 'log_probability': -29.542091973125935},\n",
       "  {'pred': '24', 'log_probability': -29.841596253216267},\n",
       "  {'pred': '26', 'log_probability': -30.97064793854952},\n",
       "  {'pred': '46', 'log_probability': -31.170544274151325},\n",
       "  {'pred': '38', 'log_probability': -32.100024826824665},\n",
       "  {'pred': '27', 'log_probability': -33.90901578217745},\n",
       "  {'pred': '6', 'log_probability': -34.77167475968599},\n",
       "  {'pred': '3', 'log_probability': -35.0326267555356},\n",
       "  {'pred': '1', 'log_probability': -35.1393743827939},\n",
       "  {'pred': '14', 'log_probability': -35.440791733562946},\n",
       "  {'pred': '23', 'log_probability': -37.9446722343564}],\n",
       " 'predictions_1': '19'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"博金翻译公司 笔记本网\"\n",
    "result = predictor.run({\"text\": text})\n",
    "for key, val in result.items():\n",
    "    if key.startswith(\"predictions\"):\n",
    "        print(key, val, id2label[val])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = predictor.preprocess({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rst[\"input_ids\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
