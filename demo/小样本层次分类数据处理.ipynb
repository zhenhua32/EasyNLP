{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网上找了个层次分类的数据\n",
    "\n",
    "处理一下, 两级的, 数据也不多, 大概 7 万条. 坑爹, 这个原始文件不太行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65605, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_level</th>\n",
       "      <th>second_level</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>休闲娱乐</td>\n",
       "      <td>影视音乐</td>\n",
       "      <td>http://www.q6636.com</td>\n",
       "      <td>奇乐电影网</td>\n",
       "      <td>奇乐电影网包含电影、电视剧、综艺、动漫、纪录片、电视直播、最新大片、最新大片电影、等热门栏目...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>休闲娱乐</td>\n",
       "      <td>影视音乐</td>\n",
       "      <td>http://video.baidu.com</td>\n",
       "      <td>百度视频搜索</td>\n",
       "      <td>百度视频搜索是业界领先的中文视频搜索引擎之一，拥有海量的中文视频资源，提供用户满意的观看体验...</td>\n",
       "      <td>热播电视剧,高清电影,好看的电视剧,好看的电影,电影天堂,电视剧排行榜,电影排行榜,百度影音...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>休闲娱乐</td>\n",
       "      <td>影视音乐</td>\n",
       "      <td>http://www.dj881.com</td>\n",
       "      <td>中国DJ前线</td>\n",
       "      <td>dj下载网为您提供破解绿色免费软件下载基地,免费绿色软件下载,共享软件基地,破解绿色软件免费下载</td>\n",
       "      <td>dj下载,免费下载,绿色下载,安全下载</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id first_level second_level                  domain   title   \n",
       "0  1        休闲娱乐         影视音乐    http://www.q6636.com   奇乐电影网  \\\n",
       "1  2        休闲娱乐         影视音乐  http://video.baidu.com  百度视频搜索   \n",
       "2  3        休闲娱乐         影视音乐    http://www.dj881.com  中国DJ前线   \n",
       "\n",
       "                                         description   \n",
       "0  奇乐电影网包含电影、电视剧、综艺、动漫、纪录片、电视直播、最新大片、最新大片电影、等热门栏目...  \\\n",
       "1  百度视频搜索是业界领先的中文视频搜索引擎之一，拥有海量的中文视频资源，提供用户满意的观看体验...   \n",
       "2   dj下载网为您提供破解绿色免费软件下载基地,免费绿色软件下载,共享软件基地,破解绿色软件免费下载   \n",
       "\n",
       "                                            keywords flag  \n",
       "0                                                NaN    3  \n",
       "1  热播电视剧,高清电影,好看的电视剧,好看的电影,电影天堂,电视剧排行榜,电影排行榜,百度影音...    2  \n",
       "2                                dj下载,免费下载,绿色下载,安全下载    1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始数据集有点坑, 用 excel 重新打开过, 然后删了几列, 不然有些列的长度不同\n",
    "raw_file = r\"G:\\dataset\\text_classify\\网页层次分类\\raw\\hierarchical_data.csv\"\n",
    "output_dir = r\"G:\\dataset\\text_classify\\网页层次分类\"\n",
    "\n",
    "df = pd.read_csv(raw_file, header=0, low_memory=False)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65581, 8)\n"
     ]
    }
   ],
   "source": [
    "is_id = re.compile(r\"^\\d+$\")\n",
    "filer = df[\"id\"].apply(lambda x:bool(is_id.match(str(x))))\n",
    "df = df[filer]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "label0_name = \"first_level\"\n",
    "label1_name = \"second_level\"\n",
    "# 先构建标签\n",
    "label_dict = defaultdict(int)\n",
    "for i, row in df.iterrows():\n",
    "    label0 = row[label0_name]\n",
    "    label1 = row[label1_name]\n",
    "    if pd.isna(label0) or pd.isna(label1):\n",
    "        continue\n",
    "    label_dict[label0] += 1\n",
    "    label_dict[f\"{label0}>{label1}\"] += 1\n",
    "\n",
    "print(len(label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'休闲娱乐': 4564,\n",
       "             '休闲娱乐>影视音乐': 1290,\n",
       "             '休闲娱乐>游戏动漫': 739,\n",
       "             '休闲娱乐>图片小说': 746,\n",
       "             '休闲娱乐>聊天交友': 552,\n",
       "             '休闲娱乐>娱乐其他': 798,\n",
       "             '休闲娱乐>休闲健身': 439,\n",
       "             '电脑网络': 8915,\n",
       "             '电脑网络>商务门户': 1673,\n",
       "             '电脑网络>网站资源': 3885,\n",
       "             '电脑网络>软硬件通信': 2010,\n",
       "             '电脑网络>网络其他': 632,\n",
       "             '电脑网络>网络营销': 715,\n",
       "             '商业经济': 22068,\n",
       "             '商业经济>农林牧渔': 999,\n",
       "             '商业经济>工业制品': 5044,\n",
       "             '商业经济>机械电子': 6360,\n",
       "             '商业经济>建筑环境': 1641,\n",
       "             '商业经济>法律金融': 1031,\n",
       "             '商业经济>商务服务': 6523,\n",
       "             '商业经济>交通物流': 470,\n",
       "             '生活服务': 17253,\n",
       "             '生活服务>生活用品': 2444,\n",
       "             '生活服务>餐饮美食': 942,\n",
       "             '生活服务>房产家居': 2438,\n",
       "             '生活服务>旅游交通': 2412,\n",
       "             '生活服务>百货购物': 1771,\n",
       "             '生活服务>医疗保健': 2888,\n",
       "             '生活服务>时尚美容': 1202,\n",
       "             '生活服务>生活常识': 832,\n",
       "             '生活服务>生活其他': 2324,\n",
       "             '教育文化': 5253,\n",
       "             '教育文化>高校教育': 770,\n",
       "             '教育文化>人力资源': 2160,\n",
       "             '教育文化>高级教育': 677,\n",
       "             '教育文化>文体艺术': 1284,\n",
       "             '教育文化>文化其他': 362,\n",
       "             '博客论坛': 2419,\n",
       "             '博客论坛>休闲娱乐': 544,\n",
       "             '博客论坛>电脑网络': 648,\n",
       "             '博客论坛>生活服务': 853,\n",
       "             '博客论坛>博客其他': 374,\n",
       "             '综合其他': 5109,\n",
       "             '综合其他>团体组织': 421,\n",
       "             '综合其他>综合网站': 2251,\n",
       "             '综合其他>个人网站': 1021,\n",
       "             '综合其他>新闻综合': 384,\n",
       "             '综合其他>其他': 1032})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = os.path.join(output_dir, \"labels.json\")\n",
    "with open(label_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    new_label_dict = {k:i for i, k in enumerate(label_dict.keys())}\n",
    "    json.dump(new_label_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65131 65131\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i, row in df.iterrows():\n",
    "    label0 = row[label0_name]\n",
    "    label1 = row[label1_name]\n",
    "    if pd.isna(label0) or pd.isna(label1):\n",
    "        continue\n",
    "\n",
    "    title = row[\"title\"]\n",
    "    description = row[\"description\"]\n",
    "    # assert pd.notna(title) or pd.notna(description)\n",
    "    title = \"\" if pd.isna(title) else title\n",
    "    description = \"\" if pd.isna(description) else description\n",
    "    content = f\"{title} {description}\".strip()\n",
    "    # 移除空格和换行符等\n",
    "    content = re.sub(r\"\\s+\", \" \", content)\n",
    "    # TODO: 很多是乱码, 应该要移除\n",
    "    if re.compile(r\"[\\u4e00-\\u9fa5]\").search(content) is None:\n",
    "        continue\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    label0_id = new_label_dict[label0]\n",
    "    label1_id = new_label_dict[f\"{label0}>{label1}\"]\n",
    "\n",
    "    X.append(content)\n",
    "    Y.append((label0_id, label1_id))\n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['奇乐电影网 奇乐电影网包含电影、电视剧、综艺、动漫、纪录片、电视直播、最新大片、最新大片电影、等热门栏目。影片使用QVOD、优酷等播放器、影片清晰流畅、网站界面清新友好、无弹窗广告的绿色电影网。每天有专人准时更新影片、是',\n",
       "  '百度视频搜索 百度视频搜索是业界领先的中文视频搜索引擎之一，拥有海量的中文视频资源，提供用户满意的观看体验。在百度视频，您可以便捷地找到海量的互联网视频，更有丰富的视频榜单、多样的视频专题满足您不同的视频观看需求。百度视频，你的视界。',\n",
       "  '中国DJ前线 dj下载网为您提供破解绿色免费软件下载基地,免费绿色软件下载,共享软件基地,破解绿色软件免费下载',\n",
       "  'BBB119免费电影 提供免费电影、最新电影、在线电影、电影下载',\n",
       "  \"56我乐网 56网是中国原创视频网站,免费上传搞笑逗趣生活视频，观看优质丰富的特色节目，关注感兴趣的原创导演和美女解说，快速分享及评论互动。'\"],\n",
       " [(0, 1), (0, 1), (0, 1), (0, 1), (0, 1)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_file = os.path.join(output_dir, \"train.csv\")\n",
    "with open(train_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for x, y in zip(train_X, train_Y):\n",
    "        f.write(f\"{x}\\t{y[0]}\\t{y[1]}\\n\")\n",
    "\n",
    "dev_file = os.path.join(output_dir, \"dev.csv\")\n",
    "with open(dev_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for x, y in zip(test_X, test_Y):\n",
    "        f.write(f\"{x}\\t{y[0]}\\t{y[1]}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 试试 paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = r\"G:\\dataset\\text_classify\\网页层次分类\\train.csv\"\n",
    "dev_file = r\"G:\\dataset\\text_classify\\网页层次分类\\test.csv\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\网页层次分类\\label.json\"\n",
    "\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    label2id = json.load(f)\n",
    "    label2id = {k: str(v) for k, v in label2id.items()}\n",
    "    id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"G:\\dataset\\text_classify\\网页层次分类\\paddlenlp\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 标签文件应该使用 ## 分隔层次的\n",
    "with open(os.path.join(output_dir, \"label.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for label in label2id.keys():\n",
    "        label = label.replace(\">\", \"##\")\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "# 训练文件中应该使用 \\t 分隔, 标签用 , 分隔\n",
    "with open(train_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "    with open(os.path.join(output_dir, \"train.txt\"), \"w\", encoding=\"utf-8\") as fw:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.split(\"\\t\")\n",
    "            label0 = id2label[line[1]].replace(\">\", \"##\")\n",
    "            label1 = id2label[line[2]].replace(\">\", \"##\")\n",
    "            fw.write(f\"{line[0]}\\t{label0},{label1}\\n\")\n",
    "\n",
    "# 测试文件中应该使用 \\t 分隔, 标签用 , 分隔\n",
    "with open(dev_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "    with open(os.path.join(output_dir, \"test.txt\"), \"w\", encoding=\"utf-8\") as fw:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.split(\"\\t\")\n",
    "            label0 = id2label[line[1]].replace(\">\", \"##\")\n",
    "            label1 = id2label[line[2]].replace(\">\", \"##\")\n",
    "            fw.write(f\"{line[0]}\\t{label0},{label1}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再换个数据集, 使用百度的事件抽取数据集 baidu_extract_2020\n",
    "\n",
    "这个数据是多标签的, 即是多层级, 也是多标签的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = r\"G:\\dataset\\text_classify\\baidu_extract_2020\\raw\\train.txt\"\n",
    "dev_file = r\"G:\\dataset\\text_classify\\baidu_extract_2020\\raw\\dev.txt\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\baidu_extract_2020\\raw\\label.txt\"\n",
    "\n",
    "label_dict = dict()\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    index = 0\n",
    "    for line in f:\n",
    "        label = line.strip().replace(\"##\", \">\")\n",
    "        label_dict[label] = index\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"G:\\dataset\\text_classify\\baidu_extract_2020\\fewshot\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 保存标签\n",
    "with open(os.path.join(output_dir, \"label.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(label_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 保存训练数据\n",
    "with open(train_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "    with open(os.path.join(output_dir, \"train.csv\"), \"w\", encoding=\"utf-8\") as fw:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.split(\"\\t\")\n",
    "            label_list = line[1].replace(\"##\", \">\")\n",
    "            label_id_list = [label_dict[x] for x in label_list.split(\",\")]\n",
    "            label_id_list = \"\\t\".join(map(str, label_id_list))\n",
    "            fw.write(f\"{line[0]}\\t{label_id_list}\\n\")\n",
    "\n",
    "# 保存测试数据\n",
    "with open(dev_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "    with open(os.path.join(output_dir, \"dev.csv\"), \"w\", encoding=\"utf-8\") as fw:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.split(\"\\t\")\n",
    "            label_list = line[1].replace(\"##\", \">\")\n",
    "            label_id_list = [label_dict[x] for x in label_list.split(\",\")]\n",
    "            label_id_list = \"\\t\".join(map(str, label_id_list))\n",
    "            fw.write(f\"{line[0]}\\t{label_id_list}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 继续换数据集, 这次是百度的事件数据集, 但是小样本版本的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = r\"G:\\dataset\\text_classify\\baidu_events\\raw\\train.txt\"\n",
    "dev_file = r\"G:\\dataset\\text_classify\\baidu_events\\raw\\dev.txt\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\baidu_events\\raw\\label.txt\"\n",
    "\n",
    "label_dict = dict()\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    index = 0\n",
    "    for line in f:\n",
    "        # == 后面的是提示标签, 就先不用了\n",
    "        label = line.strip().split(\"==\")[0].replace(\"##\", \">\")\n",
    "        label_dict[label] = index\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"G:\\dataset\\text_classify\\baidu_events\\fewshot\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 保存标签\n",
    "with open(os.path.join(output_dir, \"label.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(label_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 保存训练数据\n",
    "with open(train_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "    with open(os.path.join(output_dir, \"train.csv\"), \"w\", encoding=\"utf-8\") as fw:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.split(\"\\t\")\n",
    "            label_list = line[1].replace(\"##\", \">\")\n",
    "            label_id_list = [label_dict[x] for x in label_list.split(\",\")]\n",
    "            label_id_list = \"\\t\".join(map(str, label_id_list))\n",
    "            fw.write(f\"{line[0]}\\t{label_id_list}\\n\")\n",
    "\n",
    "# 保存测试数据\n",
    "with open(dev_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "    with open(os.path.join(output_dir, \"dev.csv\"), \"w\", encoding=\"utf-8\") as fw:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.split(\"\\t\")\n",
    "            label_list = line[1].replace(\"##\", \">\")\n",
    "            label_id_list = [label_dict[x] for x in label_list.split(\",\")]\n",
    "            label_id_list = \"\\t\".join(map(str, label_id_list))\n",
    "            fw.write(f\"{line[0]}\\t{label_id_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
