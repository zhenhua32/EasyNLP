{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import easynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easynlp.fewshot_learning.fewshot_dataset import FewshotMultiLayerBaseDataset\n",
    "# 重载\n",
    "module = importlib.import_module(FewshotMultiLayerBaseDataset.__module__)\n",
    "importlib.reload(module)\n",
    "FewshotMultiLayerBaseDataset = module.FewshotMultiLayerBaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = r\"G:\\dataset\\text_classify\\网页层次分类\\train.csv\"\n",
    "test_file = r\"G:\\dataset\\text_classify\\网页层次分类\\test.csv\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\网页层次分类\\label.json\"\n",
    "model_dir = r\"G:\\code\\pretrain_model_dir\\pai-bert-base-zh\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "tokenizer: BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 先解析 label\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    # 这边 id 是 int\n",
    "    label2id = json.load(f)\n",
    "    label2id = {k: str(v) for k, v in label2id.items()}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# 想想每一层的标签应该怎么建立, 现在假设每层都是完整的, 也就是每个样本的标签都会到最后一层\n",
    "label_enumerate_values = defaultdict(list)\n",
    "label_desc = defaultdict(list)\n",
    "for label, label_id in label2id.items():\n",
    "    label_split = label.split(\">\")\n",
    "    # 标签应该只放最后一层的\n",
    "    idx = len(label_split) - 1\n",
    "    label_enumerate_values[idx].append(label_id)\n",
    "    label_desc[idx].append(label_split[-1])\n",
    "\n",
    "# 其实应该还是有序的, 因为添加的时候是从左到右添加的\n",
    "# 计算 label_desc 的最大长度\n",
    "for idx in sorted(label_desc.keys()):\n",
    "    cur_list = label_desc[idx]\n",
    "    cur_max_len = max([len(tokenizer.tokenize(x)) for x in cur_list])\n",
    "    print(cur_max_len)\n",
    "    # 填充到最大长度\n",
    "    label_desc[idx] = [x + \"[PAD]\" * (cur_max_len - len(tokenizer.tokenize(x))) for x in cur_list]\n",
    "\n",
    "label_enumerate_values_new = []\n",
    "for idx in sorted(label_enumerate_values.keys()):\n",
    "    label_enumerate_values_new.append(\",\".join(label_enumerate_values[idx]))\n",
    "label_enumerate_values_new = \"@@\".join(label_enumerate_values_new)\n",
    "\n",
    "label_desc_new = []\n",
    "for idx in sorted(label_desc.keys()):\n",
    "    label_desc_new.append(\",\".join(label_desc[idx]))\n",
    "label_desc_new = \"@@\".join(label_desc_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,7,13,21,31,37,42@@1,2,3,4,5,6,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,29,30,32,33,34,35,36,38,39,40,41,43,44,45,46,47'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enumerate_values_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'休闲娱乐,电脑网络,商业经济,生活服务,教育文化,博客论坛,综合其他@@影视音乐[PAD],游戏动漫[PAD],图片小说[PAD],聊天交友[PAD],娱乐其他[PAD],休闲健身[PAD],商务门户[PAD],网站资源[PAD],软硬件通信,网络其他[PAD],网络营销[PAD],农林牧渔[PAD],工业制品[PAD],机械电子[PAD],建筑环境[PAD],法律金融[PAD],商务服务[PAD],交通物流[PAD],生活用品[PAD],餐饮美食[PAD],房产家居[PAD],旅游交通[PAD],百货购物[PAD],医疗保健[PAD],时尚美容[PAD],生活常识[PAD],生活其他[PAD],高校教育[PAD],人力资源[PAD],高级教育[PAD],文体艺术[PAD],文化其他[PAD],休闲娱乐[PAD],电脑网络[PAD],生活服务[PAD],博客其他[PAD],团体组织[PAD],综合网站[PAD],个人网站[PAD],新闻综合[PAD],其他[PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_desc_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****G:\\dataset\\text_classify\\网页层次分类\\train.csv\n"
     ]
    }
   ],
   "source": [
    "dataset = FewshotMultiLayerBaseDataset(\n",
    "    pretrained_model_name_or_path=model_dir,\n",
    "    data_file=train_file,\n",
    "    max_seq_length=64,\n",
    "    first_sequence=\"text\",\n",
    "    input_schema=\"text:str:1,label0:str:1,label1:str:1\",\n",
    "    label_name=\"label0,label1\",\n",
    "    label_enumerate_values=label_enumerate_values_new,\n",
    "    layer_num=2,\n",
    "    user_defined_parameters={\n",
    "        \"app_parameters\": {\n",
    "            \"pattern\": \"一条,label0,label1,的新闻,text\",\n",
    "            \"label_desc\": label_desc_new,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.masked_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'label_ids', 'mask_span_indices'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 671, 3340, 103, 103, 103, 103, 103, 103, 103, 103, 103, 4638, 3173, 7319, 1952, 1814, 7391, 2501, 5285, 4970, 2443, 1773, 2356, 1920, 1814, 1344, 1952, 1814, 7391, 2501, 5285, 4970, 3300, 7361, 1062, 1385, 855, 754, 2769, 1744, 5401, 714, 2168, 7657, 510, 5307, 3845, 1355, 6809, 776, 3823, 1538, 1765, 1277, 8024, 3315, 1062, 1385, 3221, 671, 2157, 683, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "[-100, -100, -100, 4495, 3833, 3302, 1218, 2791, 772, 2157, 2233, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[[3], [4], [5], [6], [7], [8], [9], [10], [11]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"input_ids\"])\n",
    "print(dataset[0][\"token_type_ids\"])\n",
    "print(dataset[0][\"attention_mask\"])\n",
    "print(dataset[0][\"label_ids\"])\n",
    "print(dataset[0][\"mask_span_indices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '一', '条', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '的', '新', '闻', '奥', '城', '隐', '形', '纱', '窗', '廊', '坊', '市', '大', '城', '县', '奥', '城', '隐', '形', '纱', '窗', '有', '限', '公', '司', '位', '于', '我', '国', '美', '丽', '富', '饶', '、', '经', '济', '发', '达', '京', '津', '唐', '地', '区', '，', '本', '公', '司', '是', '一', '家', '专', '[PAD]']\n",
      "['[UNK]', '[UNK]', '[UNK]', '生', '活', '服', '务', '房', '产', '家', '居', '[PAD]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(dataset[0][\"input_ids\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(dataset[0][\"label_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'label_ids', 'mask_span_indices'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=dataset.batch_fn)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([2, 64])\n",
      "attention_mask torch.Size([2, 64])\n",
      "token_type_ids torch.Size([2, 64])\n",
      "label_ids torch.Size([2, 64])\n",
      "mask_span_indices torch.Size([2, 9, 1])\n"
     ]
    }
   ],
   "source": [
    "for key, val in batch.items():\n",
    "    print(key, val.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
