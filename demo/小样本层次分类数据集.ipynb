{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import easynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easynlp.fewshot_learning.fewshot_dataset import FewshotMultiLayerBaseDataset\n",
    "# 重载\n",
    "module = importlib.import_module(FewshotMultiLayerBaseDataset.__module__)\n",
    "importlib.reload(module)\n",
    "FewshotMultiLayerBaseDataset = module.FewshotMultiLayerBaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = r\"G:\\dataset\\text_classify\\网页层次分类\\train.csv\"\n",
    "test_file = r\"G:\\dataset\\text_classify\\网页层次分类\\test.csv\"\n",
    "label_file = r\"G:\\dataset\\text_classify\\网页层次分类\\label.json\"\n",
    "model_dir = r\"G:\\code\\pretrain_model_dir\\pai-bert-base-zh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先解析 label\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    # 这边 id 是 int\n",
    "    label2id = json.load(f)\n",
    "    label2id = {k: str(v) for k, v in label2id.items()}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_enumerate_values = [[], []]\n",
    "label_desc = [[], []]\n",
    "for label, label_id in label2id.items():\n",
    "    label_split = label.split(\">\")\n",
    "    if len(label_split) == 1:\n",
    "        label_enumerate_values[0].append(label_id)\n",
    "        label_desc[0].append(label)\n",
    "    elif len(label_split) == 2:\n",
    "        label_enumerate_values[1].append(label_id)\n",
    "        label_desc[1].append(label_split[1])\n",
    "    else:\n",
    "        raise ValueError(f\"label split error, {label}\")\n",
    "\n",
    "label_enumerate_values = [\",\".join(x) for x in label_enumerate_values]\n",
    "label_desc = [\",\".join(x) for x in label_desc]\n",
    "\n",
    "label_enumerate_values = \"@@\".join(label_enumerate_values)\n",
    "label_desc = \"@@\".join(label_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,7,13,21,31,37,42@@1,2,3,4,5,6,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,29,30,32,33,34,35,36,38,39,40,41,43,44,45,46,47'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enumerate_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'休闲娱乐,电脑网络,商业经济,生活服务,教育文化,博客论坛,综合其他@@影视音乐,游戏动漫,图片小说,聊天交友,娱乐其他,休闲健身,商务门户,网站资源,软硬件通信,网络其他,网络营销,农林牧渔,工业制品,机械电子,建筑环境,法律金融,商务服务,交通物流,生活用品,餐饮美食,房产家居,旅游交通,百货购物,医疗保健,时尚美容,生活常识,生活其他,高校教育,人力资源,高级教育,文体艺术,文化其他,休闲娱乐,电脑网络,生活服务,博客其他,团体组织,综合网站,个人网站,新闻综合,其他'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****G:\\dataset\\text_classify\\网页层次分类\\train.csv\n"
     ]
    }
   ],
   "source": [
    "dataset = FewshotMultiLayerBaseDataset(\n",
    "    pretrained_model_name_or_path=model_dir,\n",
    "    data_file=train_file,\n",
    "    max_seq_length=64,\n",
    "    first_sequence=\"text\",\n",
    "    input_schema=\"text:str:1,label0:str:1,label1:str:1\",\n",
    "    label_name=\"label0,label1\",\n",
    "    label_enumerate_values=label_enumerate_values,\n",
    "    layer_num=2,\n",
    "    user_defined_parameters={\n",
    "        \"app_parameters\": {\n",
    "            \"pattern\": \"一条,label0,label1,的新闻,text\",\n",
    "            \"label_desc\": label_desc,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.masked_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'label_ids', 'mask_span_indices'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 671, 3340, 103, 103, 103, 103, 103, 103, 103, 103, 4638, 3173, 7319, 1952, 1814, 7391, 2501, 5285, 4970, 2443, 1773, 2356, 1920, 1814, 1344, 1952, 1814, 7391, 2501, 5285, 4970, 3300, 7361, 1062, 1385, 855, 754, 2769, 1744, 5401, 714, 2168, 7657, 510, 5307, 3845, 1355, 6809, 776, 3823, 1538, 1765, 1277, 8024, 3315, 1062, 1385, 3221, 671, 2157, 683, 689, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "[-100, -100, -100, 4495, 3833, 3302, 1218, 2791, 772, 2157, 2233, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[[3], [4], [5], [6], [7], [8], [9], [10]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"input_ids\"])\n",
    "print(dataset[0][\"token_type_ids\"])\n",
    "print(dataset[0][\"attention_mask\"])\n",
    "print(dataset[0][\"label_ids\"])\n",
    "print(dataset[0][\"mask_span_indices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '一', '条', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '的', '新', '闻', '奥', '城', '隐', '形', '纱', '窗', '廊', '坊', '市', '大', '城', '县', '奥', '城', '隐', '形', '纱', '窗', '有', '限', '公', '司', '位', '于', '我', '国', '美', '丽', '富', '饶', '、', '经', '济', '发', '达', '京', '津', '唐', '地', '区', '，', '本', '公', '司', '是', '一', '家', '专', '业', '[PAD]']\n",
      "['[UNK]', '[UNK]', '[UNK]', '生', '活', '服', '务', '房', '产', '家', '居', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(dataset[0][\"input_ids\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(dataset[0][\"label_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'label_ids', 'mask_span_indices'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=dataset.batch_fn)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([2, 64])\n",
      "attention_mask torch.Size([2, 64])\n",
      "token_type_ids torch.Size([2, 64])\n",
      "label_ids torch.Size([2, 64])\n",
      "mask_span_indices torch.Size([2, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "for key, val in batch.items():\n",
    "    print(key, val.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
