{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于构建文档\n",
    "\n",
    "探索命令行参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import easynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"EasyNLP Arguments\", allow_abbrev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: if you wish to use GLM models, please refer to EasyNLP/examples/appzoo_tutorials/sequence_generation/README.md!\n"
     ]
    }
   ],
   "source": [
    "from easynlp.utils.arguments import _add_easynlp_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = _add_easynlp_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--random_seed RANDOM_SEED]\n",
      "                             [--mode {train,evaluate,predict}]\n",
      "                             [--user_script USER_SCRIPT]\n",
      "                             [--user_entry_file USER_ENTRY_FILE]\n",
      "                             [--tables TABLES]\n",
      "                             [--user_defined_parameters USER_DEFINED_PARAMETERS]\n",
      "                             [--skip_first_line] [--outputs OUTPUTS]\n",
      "                             [--buckets BUCKETS] [--odps_config ODPS_CONFIG]\n",
      "                             [--app_name {text_classify,text_classify_multi_label,text_match,text_match_two_tower,vectorization,language_modeling,sequence_labeling,data_augmentation,sequence_generation,geep_classify,text2image_generation,image2text_generation,image2text_generation_vqgan,video2text_generation,clip,wukong_clip,clip4clip,machine_reading_comprehension,latent_diffusion,open_domain_dialogue,information_extraction}]\n",
      "                             [--distributed_backend {nccl,gloo}]\n",
      "                             [--sequence_length SEQUENCE_LENGTH]\n",
      "                             [--micro_batch_size MICRO_BATCH_SIZE]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             [--checkpoint_dir CHECKPOINT_DIR]\n",
      "                             [--modelzoo_base_dir MODELZOO_BASE_DIR]\n",
      "                             [--do_lower_case] [--epoch_num EPOCH_NUM]\n",
      "                             [--save_checkpoint_steps SAVE_CHECKPOINT_STEPS]\n",
      "                             [--save_all_checkpoints]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--weight_decay W]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--optimizer_type {BertAdam,Adam,AdamW,SGD}]\n",
      "                             [--warmup_proportion WARMUP_PROPORTION]\n",
      "                             [--logging_steps LOGGING_STEPS]\n",
      "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                             [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                             [--input_schema INPUT_SCHEMA]\n",
      "                             [--first_sequence FIRST_SEQUENCE]\n",
      "                             [--second_sequence SECOND_SEQUENCE]\n",
      "                             [--label_name LABEL_NAME]\n",
      "                             [--label_enumerate_values LABEL_ENUMERATE_VALUES]\n",
      "                             [--output_schema OUTPUT_SCHEMA]\n",
      "                             [--append_cols APPEND_COLS]\n",
      "                             [--predict_slice_size PREDICT_SLICE_SIZE]\n",
      "                             [--predict_queue_size PREDICT_QUEUE_SIZE]\n",
      "                             [--predict_thread_num PREDICT_THREAD_NUM]\n",
      "                             [--predict_table_read_thread_num PREDICT_TABLE_READ_THREAD_NUM]\n",
      "                             [--worker_count WORKER_COUNT]\n",
      "                             [--worker_gpu WORKER_GPU]\n",
      "                             [--master_port MASTER_PORT]\n",
      "                             [--worker_hosts WORKER_HOSTS] [--use_amp]\n",
      "                             [--use_torchacc] [--data_threads DATA_THREADS]\n",
      "                             [--mg_model]\n",
      "\n",
      "EasyNLP Arguments\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "EasyNLP:\n",
      "  --random_seed RANDOM_SEED\n",
      "                        Random seed used for python, numpy, pytorch, and cuda.\n",
      "  --mode {train,evaluate,predict}\n",
      "                        The mode of easynlp\n",
      "  --user_script USER_SCRIPT\n",
      "                        The scripts to run with easynlp\n",
      "  --user_entry_file USER_ENTRY_FILE\n",
      "                        The entry file of the scripts\n",
      "  --tables TABLES       The input table, `train_file`,`valid_file` if\n",
      "                        mode=`train`;`valid_file` if mode=`evaluate`\n",
      "  --user_defined_parameters USER_DEFINED_PARAMETERS\n",
      "                        user_defined_parameters specified by\n",
      "                        -DuserDefinedParameters\n",
      "  --skip_first_line     Whether to skip the first line in data files.\n",
      "  --outputs OUTPUTS     The output table, output prediction file\n",
      "  --buckets BUCKETS     Oss buckets\n",
      "  --odps_config ODPS_CONFIG\n",
      "                        Config file path of odps\n",
      "  --app_name {text_classify,text_classify_multi_label,text_match,text_match_two_tower,vectorization,language_modeling,sequence_labeling,data_augmentation,sequence_generation,geep_classify,text2image_generation,image2text_generation,image2text_generation_vqgan,video2text_generation,clip,wukong_clip,clip4clip,machine_reading_comprehension,latent_diffusion,open_domain_dialogue,information_extraction}\n",
      "                        name of the application\n",
      "  --distributed_backend {nccl,gloo}\n",
      "                        Which backend to use for distributed training.\n",
      "  --sequence_length SEQUENCE_LENGTH\n",
      "                        Maximum sequence length to process.\n",
      "  --micro_batch_size MICRO_BATCH_SIZE, --train_batch_size MICRO_BATCH_SIZE\n",
      "                        Batch size per model instance (local batch size).\n",
      "                        Global batch size is local batch size times data\n",
      "                        parallel size times number of micro batches.\n",
      "  --local_rank LOCAL_RANK\n",
      "                        local rank passed from distributed launcher.\n",
      "  --checkpoint_dir CHECKPOINT_DIR, --checkpoint_path CHECKPOINT_DIR\n",
      "                        The model checkpoint dir.\n",
      "  --modelzoo_base_dir MODELZOO_BASE_DIR\n",
      "                        The Base directories of modelzoo\n",
      "  --do_lower_case       Set this flag if you are using an uncased model.\n",
      "  --epoch_num EPOCH_NUM\n",
      "                        Total number of training epochs to perform.\n",
      "  --save_checkpoint_steps SAVE_CHECKPOINT_STEPS\n",
      "  --save_all_checkpoints\n",
      "                        Whether to save all checkpoints per eval steps.\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        The initial learning rate for Adam.\n",
      "  --weight_decay W, --wd W\n",
      "                        weight decay\n",
      "  --max_grad_norm MAX_GRAD_NORM, --mn MAX_GRAD_NORM\n",
      "                        Max grad norm\n",
      "  --optimizer_type {BertAdam,Adam,AdamW,SGD}, --optimizer {BertAdam,Adam,AdamW,SGD}\n",
      "                        name of the optimizer\n",
      "  --warmup_proportion WARMUP_PROPORTION\n",
      "                        Proportion of training to perform linear learning rate\n",
      "                        warmup for. E.g., 0.1 = 10% of training.\n",
      "  --logging_steps LOGGING_STEPS\n",
      "                        logging steps while training\n",
      "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n",
      "                        Number of updates steps to accumulate before\n",
      "                        performing a backward/update pass.\n",
      "  --resume_from_checkpoint RESUME_FROM_CHECKPOINT\n",
      "                        Resume training process from checkpoint\n",
      "  --input_schema INPUT_SCHEMA\n",
      "                        Only for csv data, the schema of input table\n",
      "  --first_sequence FIRST_SEQUENCE\n",
      "                        Which column is the first sequence mapping to\n",
      "  --second_sequence SECOND_SEQUENCE\n",
      "                        Which column is the second sequence mapping to\n",
      "  --label_name LABEL_NAME\n",
      "                        Which column is the label mapping to\n",
      "  --label_enumerate_values LABEL_ENUMERATE_VALUES\n",
      "                        Which column is the label mapping to\n",
      "  --output_schema OUTPUT_SCHEMA\n",
      "                        The schema of the output results\n",
      "  --append_cols APPEND_COLS\n",
      "                        The schema of the output results\n",
      "  --predict_slice_size PREDICT_SLICE_SIZE\n",
      "                        Predict slice size\n",
      "  --predict_queue_size PREDICT_QUEUE_SIZE\n",
      "                        Predict queue size\n",
      "  --predict_thread_num PREDICT_THREAD_NUM\n",
      "                        Predict Thread num\n",
      "  --predict_table_read_thread_num PREDICT_TABLE_READ_THREAD_NUM\n",
      "                        Predict Table Read Thread Num\n",
      "  --worker_count WORKER_COUNT\n",
      "                        Count of workers/servers\n",
      "  --worker_gpu WORKER_GPU\n",
      "                        Count of GPUs in each worker\n",
      "  --master_port MASTER_PORT\n",
      "                        Port of master node\n",
      "  --worker_hosts WORKER_HOSTS\n",
      "                        Worker hosts (for PAI-TF)\n",
      "  --use_amp             Enable amp, default value is False\n",
      "  --use_torchacc        Enable torchacc, default value is False\n",
      "  --data_threads DATA_THREADS\n",
      "                        Count of CPUs to process data\n",
      "  --mg_model            Use pretrained models trained with Megatron and\n",
      "                        Deepspeed\n"
     ]
    }
   ],
   "source": [
    "parser.print_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EasyNLP'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个就是 _add_easynlp_args 添加的参数\n",
    "parser._action_groups[2].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_StoreAction(option_strings=['--random_seed'], dest='random_seed', nargs=None, const=None, default=1234, type=<class 'int'>, choices=None, help='Random seed used for python, numpy, pytorch, and cuda.', metavar=None),\n",
       " _StoreAction(option_strings=['--mode'], dest='mode', nargs=None, const=None, default='train', type=<class 'str'>, choices=['train', 'evaluate', 'predict'], help='The mode of easynlp', metavar=None),\n",
       " _StoreAction(option_strings=['--user_script'], dest='user_script', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The scripts to run with easynlp', metavar=None),\n",
       " _StoreAction(option_strings=['--user_entry_file'], dest='user_entry_file', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The entry file of the scripts', metavar=None),\n",
       " _StoreAction(option_strings=['--tables'], dest='tables', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The input table, `train_file`,`valid_file` if mode=`train`;`valid_file` if mode=`evaluate`', metavar=None),\n",
       " _StoreAction(option_strings=['--user_defined_parameters'], dest='user_defined_parameters', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='user_defined_parameters specified by -DuserDefinedParameters', metavar=None),\n",
       " _StoreTrueAction(option_strings=['--skip_first_line'], dest='skip_first_line', nargs=0, const=True, default=False, type=None, choices=None, help='Whether to skip the first line in data files.', metavar=None),\n",
       " _StoreAction(option_strings=['--outputs'], dest='outputs', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The output table, output prediction file', metavar=None),\n",
       " _StoreAction(option_strings=['--buckets'], dest='buckets', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Oss buckets', metavar=None),\n",
       " _StoreAction(option_strings=['--odps_config'], dest='odps_config', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Config file path of odps', metavar=None),\n",
       " _StoreAction(option_strings=['--app_name'], dest='app_name', nargs=None, const=None, default='text_classify', type=<class 'str'>, choices=['text_classify', 'text_classify_multi_label', 'text_match', 'text_match_two_tower', 'vectorization', 'language_modeling', 'sequence_labeling', 'data_augmentation', 'sequence_generation', 'geep_classify', 'text2image_generation', 'image2text_generation', 'image2text_generation_vqgan', 'video2text_generation', 'clip', 'wukong_clip', 'clip4clip', 'machine_reading_comprehension', 'latent_diffusion', 'open_domain_dialogue', 'information_extraction'], help='name of the application', metavar=None),\n",
       " _StoreAction(option_strings=['--distributed_backend'], dest='distributed_backend', nargs=None, const=None, default='nccl', type=None, choices=['nccl', 'gloo'], help='Which backend to use for distributed training.', metavar=None),\n",
       " _StoreAction(option_strings=['--sequence_length'], dest='sequence_length', nargs=None, const=None, default=16, type=<class 'int'>, choices=None, help='Maximum sequence length to process.', metavar=None),\n",
       " _StoreAction(option_strings=['--micro_batch_size', '--train_batch_size'], dest='micro_batch_size', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, help='Batch size per model instance (local batch size). Global batch size is local batch size times data parallel size times number of micro batches.', metavar=None),\n",
       " _StoreAction(option_strings=['--local_rank'], dest='local_rank', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='local rank passed from distributed launcher.', metavar=None),\n",
       " _StoreAction(option_strings=['--checkpoint_dir', '--checkpoint_path'], dest='checkpoint_dir', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The model checkpoint dir.', metavar=None),\n",
       " _StoreAction(option_strings=['--modelzoo_base_dir'], dest='modelzoo_base_dir', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='The Base directories of modelzoo', metavar=None),\n",
       " _StoreTrueAction(option_strings=['--do_lower_case'], dest='do_lower_case', nargs=0, const=True, default=False, type=None, choices=None, help='Set this flag if you are using an uncased model.', metavar=None),\n",
       " _StoreAction(option_strings=['--epoch_num'], dest='epoch_num', nargs=None, const=None, default=3, type=<class 'int'>, choices=None, help='Total number of training epochs to perform.', metavar=None),\n",
       " _StoreAction(option_strings=['--save_checkpoint_steps'], dest='save_checkpoint_steps', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help=None, metavar=None),\n",
       " _StoreTrueAction(option_strings=['--save_all_checkpoints'], dest='save_all_checkpoints', nargs=0, const=True, default=False, type=None, choices=None, help='Whether to save all checkpoints per eval steps.', metavar=None),\n",
       " _StoreAction(option_strings=['--learning_rate'], dest='learning_rate', nargs=None, const=None, default=5e-05, type=<class 'float'>, choices=None, help='The initial learning rate for Adam.', metavar=None),\n",
       " _StoreAction(option_strings=['--weight_decay', '--wd'], dest='weight_decay', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='weight decay', metavar='W'),\n",
       " _StoreAction(option_strings=['--max_grad_norm', '--mn'], dest='max_grad_norm', nargs=None, const=None, default=1.0, type=<class 'float'>, choices=None, help='Max grad norm', metavar=None),\n",
       " _StoreAction(option_strings=['--optimizer_type', '--optimizer'], dest='optimizer_type', nargs=None, const=None, default='AdamW', type=<class 'str'>, choices=['BertAdam', 'Adam', 'AdamW', 'SGD'], help='name of the optimizer', metavar=None),\n",
       " _StoreAction(option_strings=['--warmup_proportion'], dest='warmup_proportion', nargs=None, const=None, default=0.1, type=<class 'float'>, choices=None, help='Proportion of training to perform linear learning rate warmup for. E.g., 0.1 = 10%% of training.', metavar=None),\n",
       " _StoreAction(option_strings=['--logging_steps'], dest='logging_steps', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='logging steps while training', metavar=None),\n",
       " _StoreAction(option_strings=['--gradient_accumulation_steps'], dest='gradient_accumulation_steps', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='Number of updates steps to accumulate before performing a backward/update pass.', metavar=None),\n",
       " _StoreAction(option_strings=['--resume_from_checkpoint'], dest='resume_from_checkpoint', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Resume training process from checkpoint', metavar=None),\n",
       " _StoreAction(option_strings=['--input_schema'], dest='input_schema', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Only for csv data, the schema of input table', metavar=None),\n",
       " _StoreAction(option_strings=['--first_sequence'], dest='first_sequence', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Which column is the first sequence mapping to', metavar=None),\n",
       " _StoreAction(option_strings=['--second_sequence'], dest='second_sequence', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Which column is the second sequence mapping to', metavar=None),\n",
       " _StoreAction(option_strings=['--label_name'], dest='label_name', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Which column is the label mapping to', metavar=None),\n",
       " _StoreAction(option_strings=['--label_enumerate_values'], dest='label_enumerate_values', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Which column is the label mapping to', metavar=None),\n",
       " _StoreAction(option_strings=['--output_schema'], dest='output_schema', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='The schema of the output results', metavar=None),\n",
       " _StoreAction(option_strings=['--append_cols'], dest='append_cols', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The schema of the output results', metavar=None),\n",
       " _StoreAction(option_strings=['--predict_slice_size'], dest='predict_slice_size', nargs=None, const=None, default=4096, type=<class 'int'>, choices=None, help='Predict slice size', metavar=None),\n",
       " _StoreAction(option_strings=['--predict_queue_size'], dest='predict_queue_size', nargs=None, const=None, default=1024, type=<class 'int'>, choices=None, help='Predict queue size', metavar=None),\n",
       " _StoreAction(option_strings=['--predict_thread_num'], dest='predict_thread_num', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, help='Predict Thread num', metavar=None),\n",
       " _StoreAction(option_strings=['--predict_table_read_thread_num'], dest='predict_table_read_thread_num', nargs=None, const=None, default=16, type=<class 'int'>, choices=None, help='Predict Table Read Thread Num', metavar=None),\n",
       " _StoreAction(option_strings=['--worker_count'], dest='worker_count', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='Count of workers/servers', metavar=None),\n",
       " _StoreAction(option_strings=['--worker_gpu'], dest='worker_gpu', nargs=None, const=None, default=-1, type=<class 'int'>, choices=None, help='Count of GPUs in each worker', metavar=None),\n",
       " _StoreAction(option_strings=['--master_port'], dest='master_port', nargs=None, const=None, default=23456, type=<class 'int'>, choices=None, help='Port of master node', metavar=None),\n",
       " _StoreAction(option_strings=['--worker_hosts'], dest='worker_hosts', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Worker hosts (for PAI-TF)', metavar=None),\n",
       " _StoreTrueAction(option_strings=['--use_amp'], dest='use_amp', nargs=0, const=True, default=False, type=None, choices=None, help='Enable amp, default value is False', metavar=None),\n",
       " _StoreTrueAction(option_strings=['--use_torchacc'], dest='use_torchacc', nargs=0, const=True, default=False, type=None, choices=None, help='Enable torchacc, default value is False', metavar=None),\n",
       " _StoreAction(option_strings=['--data_threads'], dest='data_threads', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, help='Count of CPUs to process data', metavar=None),\n",
       " _StoreTrueAction(option_strings=['--mg_model'], dest='mg_model', nargs=0, const=True, default=False, type=None, choices=None, help='Use pretrained models trained with Megatron and Deepspeed', metavar=None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser._action_groups[2]._group_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--random_seed'], dest='random_seed', nargs=None, const=None, default=1234, type=<class 'int'>, choices=None, help='Random seed used for python, numpy, pytorch, and cuda.', metavar=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser._action_groups[2]._group_actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'option_strings': ['--random_seed'],\n",
       " 'dest': 'random_seed',\n",
       " 'nargs': None,\n",
       " 'const': None,\n",
       " 'default': 1234,\n",
       " 'type': int,\n",
       " 'choices': None,\n",
       " 'required': False,\n",
       " 'help': 'Random seed used for python, numpy, pytorch, and cuda.',\n",
       " 'metavar': None,\n",
       " 'container': <argparse._ArgumentGroup at 0x248a8cd8610>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser._action_groups[2]._group_actions[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choices None\n",
      "const None\n",
      "container <argparse._ArgumentGroup object at 0x00000248A8CD8610>\n",
      "default 1234\n",
      "dest random_seed\n",
      "help Random seed used for python, numpy, pytorch, and cuda.\n",
      "metavar None\n",
      "nargs None\n",
      "option_strings ['--random_seed']\n",
      "required False\n",
      "type <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "dir(parser._action_groups[2]._group_actions[0])\n",
    "for attr in dir(parser._action_groups[2]._group_actions[0]):\n",
    "    if not attr.startswith(\"_\"):\n",
    "        print(attr, getattr(parser._action_groups[2]._group_actions[0], attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这应该能保存成字典, 然后用 pandas 读取\n",
    "lines = []\n",
    "for action in parser._action_groups[2]._group_actions:\n",
    "    if not action.dest.startswith(\"_\"):\n",
    "        lines.append(action.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>option_strings</th>\n",
       "      <th>dest</th>\n",
       "      <th>nargs</th>\n",
       "      <th>const</th>\n",
       "      <th>default</th>\n",
       "      <th>type</th>\n",
       "      <th>choices</th>\n",
       "      <th>required</th>\n",
       "      <th>help</th>\n",
       "      <th>metavar</th>\n",
       "      <th>container</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[--random_seed]</td>\n",
       "      <td>random_seed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1234</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Random seed used for python, numpy, pytorch, a...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;argparse._ArgumentGroup object at 0x00000248A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[--mode]</td>\n",
       "      <td>mode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>[train, evaluate, predict]</td>\n",
       "      <td>False</td>\n",
       "      <td>The mode of easynlp</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;argparse._ArgumentGroup object at 0x00000248A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[--user_script]</td>\n",
       "      <td>user_script</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>The scripts to run with easynlp</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;argparse._ArgumentGroup object at 0x00000248A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    option_strings         dest  nargs const default           type   \n",
       "0  [--random_seed]  random_seed    NaN  None    1234  <class 'int'>  \\\n",
       "1         [--mode]         mode    NaN  None   train  <class 'str'>   \n",
       "2  [--user_script]  user_script    NaN  None    None  <class 'str'>   \n",
       "\n",
       "                      choices  required   \n",
       "0                        None     False  \\\n",
       "1  [train, evaluate, predict]     False   \n",
       "2                        None     False   \n",
       "\n",
       "                                                help metavar   \n",
       "0  Random seed used for python, numpy, pytorch, a...    None  \\\n",
       "1                                The mode of easynlp    None   \n",
       "2                    The scripts to run with easynlp    None   \n",
       "\n",
       "                                           container  \n",
       "0  <argparse._ArgumentGroup object at 0x00000248A...  \n",
       "1  <argparse._ArgumentGroup object at 0x00000248A...  \n",
       "2  <argparse._ArgumentGroup object at 0x00000248A...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lines)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"easynlp_args.csv\", index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
